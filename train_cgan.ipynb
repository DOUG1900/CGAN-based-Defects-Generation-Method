{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-12\n",
    "\n",
    "train_picture_path = './/dataset2//train//0.normal//'\n",
    "label_picture_path = './/dataset2//train//1.abnormal//'\n",
    "train_save_path = './/train_save//'\n",
    "model_save_path = './save_model/'\n",
    "\n",
    "train_picture_list = glob.glob(os.path.join(train_picture_path, \"*\"))\n",
    "label_picture_list = glob.glob(os.path.join(label_picture_path, \"*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm(inp,name=\"batch_norm\"):\n",
    "    batch_norm_fi = tf.keras.layers.BatchNormalization()(inp, training=True)\n",
    "    return batch_norm_fi\n",
    "\n",
    "def lrelu(x, leak=0.2, name = \"lrelu\"):\n",
    "    return tf.maximum(x, leak*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_input = tf.keras.Input(shape=(256,256,3), name='train_img')\n",
    "c1 = tf.keras.layers.Conv2D(filters=64,kernel_size=4,strides=2,padding='same',input_shape=[256,256,3])(gen_input)\n",
    "b1 = batch_norm(c1)\n",
    "#[1,128,128,64]\n",
    "c2 = tf.keras.layers.Conv2D(filters=128,kernel_size=4,strides=2,padding='same',use_bias=False)(lrelu(b1))\n",
    "b2 = batch_norm(c2)\n",
    "#[1,64,64,256]\n",
    "c3 = tf.keras.layers.Conv2D(filters=256,kernel_size=4,strides=2,padding='same',use_bias=False)(lrelu(b2))\n",
    "b3 = batch_norm(c3)\n",
    "#[1,32,32,256]\n",
    "c4 = tf.keras.layers.Conv2D(filters=512,kernel_size=4,strides=2,padding='same',use_bias=False)(lrelu(b3))\n",
    "b4 = batch_norm(c4)\n",
    "#[1,16,16,512]\n",
    "c5 = tf.keras.layers.Conv2D(filters=512,kernel_size=4,strides=2,padding='same',use_bias=False)(lrelu(b4))\n",
    "b5 = batch_norm(c5)\n",
    "#[1,8,8,512]\n",
    "c6 = tf.keras.layers.Conv2D(filters=512,kernel_size=4,strides=2,padding='same',use_bias=False)(lrelu(b5))\n",
    "b6 = batch_norm(c6)\n",
    "#[1,4,4,512]\n",
    "c7 = tf.keras.layers.Conv2D(filters=512,kernel_size=4,strides=2,padding='same',use_bias=False)(lrelu(b6))\n",
    "b7 = batch_norm(c7)\n",
    "#[1,2,2,512]\n",
    "c8 = tf.keras.layers.Conv2D(filters=512,kernel_size=4,strides=2,padding='same',use_bias=False)(lrelu(b7))\n",
    "b8 = batch_norm(c8)\n",
    "#[1,1,1,512]\n",
    "\n",
    "d1 = tf.keras.layers.Conv2DTranspose(512,kernel_size=4,strides=2,padding='same',use_bias=False)(b8)\n",
    "d1 = tf.nn.dropout(d1, 0.5)\n",
    "d1 = tf.concat([batch_norm(d1, name='g_bn_d1'), b7],3)\n",
    "#[1,2,2,512]\n",
    "d2 = tf.keras.layers.Conv2DTranspose(512,kernel_size=4,strides=2,padding='same',use_bias=False)(tf.nn.relu(d1))\n",
    "d2 = tf.nn.dropout(d2, 0.5)\n",
    "d2 = tf.concat([batch_norm(d2, name='g_bn_d2'), b6],3)\n",
    "#[1,4,4,512]\n",
    "d3 = tf.keras.layers.Conv2DTranspose(512,kernel_size=4,strides=2,padding='same',use_bias=False)(tf.nn.relu(d2))\n",
    "d3 = tf.nn.dropout(d3, 0.5)\n",
    "d3 = tf.concat([batch_norm(d3, name='g_bn_d3'), b5],3)\n",
    "#[1,8.8.512]\n",
    "d4 = tf.keras.layers.Conv2DTranspose(512,kernel_size=4,strides=2,padding='same',use_bias=False)(tf.nn.relu(d3))\n",
    "d4 = tf.concat([batch_norm(d4, name='g_bn_d4'), b4],3)\n",
    "#[1,16,16,512]\n",
    "d5 = tf.keras.layers.Conv2DTranspose(256,kernel_size=4,strides=2,padding='same',use_bias=False)(tf.nn.relu(d4))\n",
    "d5 = tf.concat([batch_norm(d5, name='g_bn_d5'), b3],3)\n",
    "#[1,32,32,256]\n",
    "d6 = tf.keras.layers.Conv2DTranspose(128,kernel_size=4,strides=2,padding='same',use_bias=False)(tf.nn.relu(d5))\n",
    "d6 = tf.concat([batch_norm(d6, name='g_bn_d6'), b2],3)\n",
    "#[1,64,64,128]\n",
    "d7 = tf.keras.layers.Conv2DTranspose(64,kernel_size=4,strides=2,padding='same',use_bias=False)(tf.nn.relu(d6))\n",
    "d7 = tf.concat([batch_norm(d7, name='g_bn_d7'), b1],3)\n",
    "#[1,128,128,64]\n",
    "d8 = tf.keras.layers.Conv2DTranspose(3,kernel_size=4,strides=2,padding='same',use_bias=False)(tf.nn.relu(d7))\n",
    "gen_out = tf.nn.tanh(d8)\n",
    "#[1.256,256,3]\n",
    "gen_model = tf.keras.Model(inputs=gen_input, outputs=gen_out, name='gen_model')\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(2*1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_input = tf.keras.Input(shape=(256,256,6), name='train_img')\n",
    "h1 = tf.keras.layers.Conv2D(64,(4,4),strides=(2,2),padding='same',input_shape=[256,256,3])(dis_input)\n",
    "h1 = lrelu(h1)\n",
    "#1*128*128*64\n",
    "h2 = tf.keras.layers.Conv2D(128,(4,4),strides=(2,2),padding='same',use_bias=False)(h1)\n",
    "h2 = batch_norm(h2)\n",
    "h2 = lrelu(h2)\n",
    "#1*64*64*128\n",
    "h3 = tf.keras.layers.Conv2D(256,(4,4),strides=(2,2),padding='same',use_bias=False)(h2)\n",
    "h3 = batch_norm(h3)\n",
    "h3 = lrelu(h3)\n",
    "#1*32*32*256\n",
    "h4 = tf.keras.layers.Conv2D(512,(4,4),strides=(1,1),padding='same',use_bias=False)(h3)\n",
    "h4 = batch_norm(h4)\n",
    "h4 = lrelu(h4)\n",
    "#1*32*32*512\n",
    "output = tf.keras.layers.Conv2D(1,(4,4),strides=(1,1),padding='same',use_bias=False)(h4)\n",
    "#1*32*32*1\n",
    "dis_out = tf.sigmoid(output)\n",
    "dis_model = tf.keras.Model(inputs=dis_input, outputs=dis_out, name='dis_model')\n",
    "\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(2*1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_loss(src, dst):\n",
    "    return tf.reduce_mean(tf.abs(src - dst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch_picture,batch_label,count):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_label = gen_model(batch_picture)\n",
    "        dis_real = dis_model(tf.concat([batch_picture, batch_label], 3))\n",
    "        dis_fake = dis_model(tf.concat([batch_picture, gen_label], 3))\n",
    "        gen_loss_L1 = tf.reduce_mean(l1_loss(gen_label, batch_label))\n",
    "        gen_loss = tf.reduce_mean(-tf.math.log(dis_fake + EPS)) + 100 * gen_loss_L1\n",
    "        #+ 1*tf.reduce_mean(l1_loss(gen_label, batch_label))\n",
    "        dis_loss = tf.reduce_mean(-(tf.math.log(dis_real + EPS) + tf.math.log(1 - dis_fake + EPS)))\n",
    "        \n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, gen_model.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(dis_loss, dis_model.trainable_variables)\n",
    "\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, dis_model.trainable_variables))\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, gen_model.trainable_variables))\n",
    "    \n",
    "    return gen_loss,dis_loss,gen_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(runstep):\n",
    "    test_picture_path = './dataset2/train/0.normal/'\n",
    "    test_save_path = './test_save/'\n",
    "    gen_model.load_weights(model_save_path)\n",
    "    test_picture_list = glob.glob(os.path.join(test_picture_path, \"*\"))\n",
    "    for step in range(len(test_picture_list)):\n",
    "        testimg_path = test_picture_list[step]\n",
    "        pic_name, _ = os.path.splitext(os.path.basename(testimg_path))\n",
    "        picture =  cv2.imread(testimg_path)\n",
    "        height = picture.shape[0] # height\n",
    "        width = picture.shape[1] # width\n",
    "        picture_resize_t = cv2.resize(picture, (256, 256))\n",
    "        picture_resize = picture_resize_t / 127.5 - 1.\n",
    "        batch_picture = np.expand_dims(np.array(picture_resize).astype(np.float32), axis = 0)\n",
    "        gen_label = gen_model(batch_picture)\n",
    "        out_img = (gen_label[0] + 1.) * 127.5\n",
    "        out_img = out_img.numpy()\n",
    "        out_img = cv2.resize(out_img, (width, height))\n",
    "        write_image_name = test_save_path + str(runstep) + '_' + str(step) + \".jpg\"\n",
    "        # write_image_name = test_save_path + pic_name + \".png\"\n",
    "        cv2.imwrite(write_image_name, out_img)\n",
    "        # print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    gen_ls = []\n",
    "    dis_ls = []\n",
    "    counter = 0\n",
    "    gen_model.load_weights(model_save_path)\n",
    "    for epoch in range(0,100):\n",
    "        random.shuffle(train_picture_list)\n",
    "        for step in range(len(train_picture_list)):\n",
    "            counter += 1\n",
    "            img_path = train_picture_list[step]\n",
    "            pic_name, _ = os.path.splitext(os.path.basename(img_path))\n",
    "            label_path = label_picture_path + pic_name + '.jpg'\n",
    "            picture =  cv2.imread(img_path)\n",
    "            label =  cv2.imread(label_path)\n",
    "            height = picture.shape[0] #得到图片的高\n",
    "            width = picture.shape[1] #得到图片的宽\n",
    "            picture_resize_t = cv2.resize(picture, (256, 256))\n",
    "            picture_resize = picture_resize_t / 127.5 - 1.\n",
    "            label_resize_t = cv2.resize(label, (256, 256))\n",
    "            label_resize = label_resize_t / 127.5 - 1.\n",
    "            batch_picture = np.expand_dims(np.array(picture_resize).astype(np.float32), axis = 0)\n",
    "            batch_label = np.expand_dims(np.array(label_resize).astype(np.float32), axis = 0)\n",
    "            gen_loss,dis_loss,gen_label = train_step(batch_picture,batch_label,counter) \n",
    "            gen_ls.append(gen_loss)\n",
    "            dis_ls.append(dis_loss)\n",
    "            if counter % 500 == 0:\n",
    "                evaluate(counter)\n",
    "                gen_model.save_weights(model_save_path)\n",
    "            if counter % 100 == 0:\n",
    "                out_img = (gen_label[0] + 1.) * 127.5\n",
    "                out_img = out_img.numpy() \n",
    "                out_img = cv2.resize(out_img, (width, height))\n",
    "                #save_img = np.concatenate((picture_resize_t,out_img,label_resize_t), axis=1)\n",
    "                write_image_name = train_save_path + str(counter) + \".jpg\"\n",
    "                cv2.imwrite(write_image_name, out_img)\n",
    "            gen_model.save_weights(model_save_path)\n",
    "            print('epoch {:d} step {:d} gen_loss = {:.3f}, dis_loss = {:.3f}'.format(epoch, step, gen_loss, dis_loss))\n",
    "    return gen_ls, dis_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_loss,dis_loss = train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of the training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dis_loss)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
